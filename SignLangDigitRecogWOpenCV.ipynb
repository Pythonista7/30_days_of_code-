{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining Camera feed to a keras model through OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 3 of 30 days of code.\n",
    "\n",
    "As I was learning more and more about Image Processing i was curious to see if I could pipeline the video feed from my video camera , process it to Greyscale, resize it and pass it through a model to predict what number my hand posture represented.The machine learning part was already done before, you can find it on my github account [here](https://github.com/Pythonista7/Sign_Language_Digit_Recognition),proper step by step guide to build a CNN for image recognition.\n",
    "\n",
    "   I had already save a trained model for future use(Sign86.h5),download it from here.Oh boy sure did it come to use now.\n",
    "\n",
    "**Note**<br>\n",
    "Additional Dependencies : Keras  \n",
    "Press 'q' to close all active camera windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.models import load_model\n",
    "\n",
    "#My pre-trained model.\n",
    "\n",
    "l5_cnn=load_model('/assets/Sign86.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam=cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    _,frame=cam.read(0)\n",
    "    if _ == False:\n",
    "        continue\n",
    "    hsv=cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #HSV range for human skin is as about: 16,  66, 255\n",
    "    low=np.array([5,  66, 70])\n",
    "    up=np.array([25, 159, 230])\n",
    "    \n",
    "    #Creating a mask for the color range we need to pick up\n",
    "    mask=cv2.inRange(hsv,low,up)\n",
    "    \n",
    "    res=cv2.bitwise_and(frame,frame,mask=mask)\n",
    "    \n",
    "    cv2.imshow('feed',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    \n",
    "    #Creating a ROI to extract requried part of image\n",
    "    img=res[190:390,125:425]\n",
    "    \n",
    "    #Font style for our prediction to be displayed on the feed window\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "    \n",
    "    #Resizing the image to fit into our CNN\n",
    "    img=cv2.resize(res,(64,64),interpolation=cv2.INTER_AREA)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_HSV2BGR)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #This helps increase contrast\n",
    "    img=cv2.add(img,img)\n",
    "    \n",
    "    \n",
    "    #Using a Keras util to prepare image to feed into the CNN\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    #Printing the Prediction of a frame on top of it\n",
    "    txt=str(l5_cnn.predict_classes(x))\n",
    "    cv2.putText(res,txt,(20,40),font,3,(255,255,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    #cv2.imshow('frame',frame)\n",
    "    \n",
    "    #The img window show what is feed to the CNN\n",
    "    cv2.imshow('img',img)\n",
    "    \n",
    "    #The result is the mask with the prediction printed on the top right\n",
    "    cv2.imshow('result',res)\n",
    "    \n",
    "    \n",
    "    k=cv2.waitKey(5)&0xFF\n",
    "    if(k==27):\n",
    "        break\n",
    "    #Press 'q' to quit\n",
    "    #The frames per second can be controlled by increasing the key wait time\n",
    "    if(cv2.waitKey(100) & 0xFF==ord('q')):\n",
    "        break\n",
    "    \n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay the prediction might not be great but its a big step in the right direction.I will seriously consider updating this file along with the CNN repo once I'm comfortable with openCV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
